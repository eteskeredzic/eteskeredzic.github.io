[{"content":"\nFor a long time, one of my favorite hobbies was gaming, and one of my favorite games was DotA 2. According to Steam, I\u0026rsquo;ve spent thousands of hours playing it - and whether alone or with friends, I always had a blast!\nThe premise of the game is deceptively simple: Two teams of 5 players, each controlling a hero, need to defend their base (so-called Ancient), while at the same time trying to destroy the enemy base. That\u0026rsquo;s the basic idea - you now understand the game. But, given over a hundred heroes, items, play-styles, etc., DotA is actually extremely complex, and virtually no two games are the same. It\u0026rsquo;s easy to understand, but hard to master - kinda like chess.\nOn the topic of chess, I have recently watched a great video titled The rarest move in chess The rarest move in chess (video by Paralogical)\rThe rarest move in chess (video by Paralogical)\r. It\u0026rsquo;s a fascinating exploration of chess games documented online. So, if we can ask What is the rarest move in chess?, then naturally\u0026hellip;\nWhat is the rarest game of DotA 2?\rSince this question cannot be answered without both combinatorics AND programming, I decided to find out!\nA game of infinite variety There are some caveats to this question, namely:\nWe can only analyze games that have been documented online. To do that, I\u0026rsquo;ll need a dataset of DotA 2 matches - the larger the better. A game of DotA 2 has many parameters - hero picks, item builds, player positions, etc. In order to keep things manageable, I will only consider hero picks. This means that two games are the same if the same heroes have been picked by the same teams (so side/team matters!). In addition, the sides in DotA are not symmetrical, so I\u0026rsquo;m treating drafts where some (or all) heroes are swapped between sides as different drafts. I\u0026rsquo;ll look into these two points in more detail.\nGetting game data Fortunately, there\u0026rsquo;s a great project called OpenDota\rOpenDota project\rOpenDota project\r, which provides open-source data on DotA 2 matches. The folks maintaining the project have released two comprehensive data dumps: one from 2015\rDecember 2015 Data Dump\rDecember 2015 Data Dump\r, containing 3.5 million matches, and another one from 2017\rData Dump (March 2011 to March 2016)\rData Dump (March 2011 to March 2016)\r, with over a billion matches.\nThe bigger dataset is not available (the data is no longer being seeded via torrents), so the smaller one will have to do (at least for now). It\u0026rsquo;s available as a gzipped JSON file (~100 GB). The structure of this JSON file is described on the OpenDota Github page\rOpenDota GitHub Repository - JSON Data Dump description\rOpenDota GitHub Repository - JSON Data Dump description\r.\nAfter downloading the data dump, I used Python to parse through the data in a streaming fashion (you really want to stream data for datasets this big - have you seen these RAM prices?). The only relevant information for this little experiment are the hero drafts, so I\u0026rsquo;ve disregarded all other data. What I ended up with was a NDJSON file containing 3 566 804 drafts.\nHere\u0026rsquo;s the script that handles the streaming+parsing of the data (for brevity, error handling has been omitted). The following code reads the JSON, and outputs the relevant draft data for every match, in NDJSON format:\n#!/usr/bin/env python3 import sys import json import ijson from tqdm import tqdm def main() -\u0026gt; None: \u0026#34;\u0026#34;\u0026#34; Streams through JSON array; outputs relevant match data as NDJSON. Data to output for every match: - match_id - game_mode - players: list of dicts with hero_id and player_slot \u0026#34;\u0026#34;\u0026#34; items = ijson.items(sys.stdin, \u0026#34;item\u0026#34;) for m in tqdm(items, unit=\u0026#34;matches\u0026#34;, mininterval=25.0): match_id = m.get(\u0026#34;match_id\u0026#34;) game_mode = m.get(\u0026#34;game_mode\u0026#34;) players = m.get(\u0026#34;players\u0026#34;) or [] out_players = [] for p in players: hero_id = p.get(\u0026#34;hero_id\u0026#34;) player_slot = p.get(\u0026#34;player_slot\u0026#34;) out_players.append( { \u0026#34;hero_id\u0026#34;: hero_id, \u0026#34;player_slot\u0026#34;: player_slot, } ) out = { \u0026#34;match_id\u0026#34;: match_id, \u0026#34;game_mode\u0026#34;: game_mode, \u0026#34;players\u0026#34;: out_players, } sys.stdout.write(json.dumps(out, separators=(\u0026#34;,\u0026#34;, \u0026#34;:\u0026#34;))+\u0026#34;\\n\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() # invoke script with: # gzcat yasp-dump.json.gz | python3 main.py \u0026gt; matches.ndjson Now I have an NDJSON file (around 1.32 GB) containing the drafts. For every match, I have the match ID, game mode, and the hero picks for both teams (player team is indicated by player_slot).\nNote: While this dataset is great, it does have one glaring issue - 3.5 million matches is relatively small compared to the actual number of DotA 2 games played since the game\u0026rsquo;s release (8.6 billion). Many drafts that have been played in the wild are most likely not included in this dataset. However, as we\u0026rsquo;ll see later, even with a hypothetical perfect dataset, we have not even scratched the surface of all possible drafts. Before looking at this data though, there\u0026rsquo;s a fundamental question that needs to be answered: How many different drafts are even possible?\nA brief detour into combinatorics I\u0026rsquo;m only looking into hero picks, so I can calculate the number of possible hero drafts for each team. In a standard game, the teams (Dire and Radiant) each pick 5 heroes from a pool of heroes. The order does not matter, and a hero can only be picked once.\nIn combinatorics, the number of ways to choose k elements from a set of n elements is given by the binomial coefficient, often read as \u0026ldquo;n choose k\u0026rdquo;. The formula is quite simple:\n$${n \\choose k} = \\frac{n!}{k! * (n - k)!}$$\rSince our dataset is from December of 2015, the hero pool (n) consists of 111 heroes. So the number of possible 10-hero drafts is: $${111 \\choose 10} = 51\\ 540\\ 966\\ 982\\ 791$$\r\u0026hellip;or 51 trillion 540 billion 966 million 982 thousand 791 possible drafts! But hold up - that\u0026rsquo;s just the number of ways to pick 10 heroes. This calculation does not take into account which team picked which heroes. So, our actual formula is:\n$${111 \\choose 5} * {106 \\choose 5} = 12\\ 988\\ 323\\ 679\\ 663\\ 332$$\r\u0026hellip;or\u0026hellip;\r12 quadrillion 988 trillion 323 billion 679 million 663 thousand 332 possible drafts!\rThat number is just absurdly large. To put things into perspective, if we started 100 games of DotA 2 every second, we would need a little over 4.1 million years in order to play through every possible draft. Furthermore, with every new hero added to the game, this number grows larger - not linearly, but combinatorially!\nAnother way to grasp this number is to compare it to the actual amount of DotA 2 games played. As of writing this article, there have been approximately 8.6 billion matches played (this number also includes silly game modes like ability draft). DotA 2 released in 2013, so with this amount of games in 13 years, we will need another 20 million years before we reach this number!\nThis is great news! Since only a tiny fraction of all possible drafts has been played, there must be drafts that have never (and will never) be played. Which implies a rarest game of DotA 2 exists!\nFinding the rarest game The data is ready, and I know for certain that not all possible drafts have been played. I can now find the rarest game of DotA 2!\nSince the data has been nicely parsed, this is not that hard. I\u0026rsquo;ve written a simple Python script that streams through our NDJSON, and counts the occurences of each draft, using the neat built-in Counter class that Python offers. I expect the number of unique drafts to be far smaller than 3.5 million - this fits neatly into memory - for larger datasets, solutions like DuckDB or SQLite can help.\nFirst, I extract the drafts from the dataset, returning them as two tuples of 5 elements each (the hero IDs - which are constant over time and never change) - the tuples have been sorted, so the ordering inside a specific team does not matter.\nThe following function handles the described draft extraction:\ndef extract_draft(match: dict) -\u0026gt; tuple[tuple[int, ...], tuple[int, ...]] | None: \u0026#34;\u0026#34;\u0026#34; Return the draft of a match as two sorted tuples (Radiant, Dire). If the match does not have a complete 5v5 draft, return None. Radiant is identified by player_slot 0-4, Dire by 128-132. \u0026#34;\u0026#34;\u0026#34; players: list[dict] = match.get(\u0026#34;players\u0026#34;, []) radiant_heroes = [] dire_heroes = [] for player in players: hero_id = player.get(\u0026#34;hero_id\u0026#34;) slot = player.get(\u0026#34;player_slot\u0026#34;, 0) if hero_id is None or hero_id == 0: continue # Slots 0-4 are Radiant, 128-132 are Dire if slot \u0026lt; 128: radiant_heroes.append(hero_id) else: dire_heroes.append(hero_id) # Only return complete 5v5 drafts if len(radiant_heroes) == 5 and len(dire_heroes) == 5: return ( tuple(sorted(radiant_heroes)), tuple(sorted(dire_heroes)), ) return None The two tuples (well, tuple of tuples) can now be used as the key for the Counter. Let\u0026rsquo;s open the NDJSON file, stream it line by line (that\u0026rsquo;s the beauty of NDJSON), extract the draft, and just attach it to our counter. Also, the code keeps track of the match ID, so that I can access the specific matches of interest later on.\nI wrote a function that does just that:\ndef parse_matches(filepath: Path,) -\u0026gt; tuple[Counter, dict]: \u0026#34;\u0026#34;\u0026#34; Parses the NDJSON file line-by-line, and counts the occurences of each draft. Returns a Counter of drafts and a dict mapping drafts to match IDs. \u0026#34;\u0026#34;\u0026#34; draft_counter: Counter[tuple] = Counter() draft_match_ids: dict[tuple, int] = {} with open(filepath, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: for line in f: line = line.strip() match: dict = json.loads(line) draft = extract_draft(match) if draft is not None: draft_counter[draft] += 1 if draft not in draft_match_ids: draft_match_ids[draft] = match.get(\u0026#34;match_id\u0026#34;, 0) return draft_counter, draft_match_ids After some additional code to parse the results, we have our answer:\nThe rarest draft in our dataset has been played only once and it is\u0026hellip;drumroll please\u0026hellip; ü•Åü•Åü•Å\r\u0026hellip;actually, there\u0026rsquo;s a whole bunch of them. This should not be surprising for those who have followed along on the combinatorics part. The number of possible drafts is practically infinitely larger than what is available in the dataset. In fact, out of 3.5 million matches, 3 550 920 of them have drafts that occur only once in the dataset (which is around 99.6%).\nHere\u0026rsquo;s one of the drafts that has been played only once:\nThis match has the ID 2001385642, and you can actually check it out on Dotabuff: https://www.dotabuff.com/matches/2001385642\nConsidering the draft, it\u0026rsquo;s no wonder that Dire stomped this game after only 28 minutes of playtime.\nHere\u0026rsquo;s the same stats, for two game modes specifically: All Pick and Ranked Competitive. I\u0026rsquo;ve also included the most common draft:\nGame Mode Valid 5v5 drafts Unique drafts Drafts appearing exactly once Most common draft (occurences) All Pick 1 525 451 1 525 357 1 525 326 31 Ranked 1 547 377 1 547 375 1 547 373 2 The most common draft in All Pick consists of the following lineup:\nRadiant: Enigma, Beastmaster, Luna, Nature\u0026rsquo;s Prophet, Huskar Dire: Morphling, Weaver, Keeper of the Light, Io, Medusa For Ranked Competitive, the most common draft is (and I\u0026rsquo;m really glad to see my GOAT Pugna here):\nRadiant: Zeus, Warlock, Silencer, Troll Warlord, Bristleback Dire: Axe, Sniper, Pugna, Omniknight, Undying Future work This was a fun excuse for me to talk about combinatorics! However, there\u0026rsquo;s a lot more that can be done here:\nAnalyze the larger dataset (\u0026gt;1 billion matches) if it becomes available again - if someone from OpenDota reads this, please reach out! Extract more fun insights from the dataset - what end-game item has been bought the most times? How many times has poor Roshan died? Longest game? Game with most kills? Player with highest cummulative stun duration? You get the idea. Visualize the distribution of draft frequencies: How many drafts have been played once, twice, etc.? Conclusion Games like DotA 2 can be played for thousands of hours, not because they are random, but because of the mind-bogglingly large universe of possible games, so huge that even playing billions of matches barely explore it.\nRealistically, because of things like win rates, meta-game, etc., you will see the same drafts multiple times when playing. However, even if you started playing now and kept at it all the way until the heat death of the Universe, you will never play every game.\nSo, what is the rarest game of DotA 2? Well, there are trillions, and they are waiting for you to play them!\rReferences\r","permalink":"https://eteskeredzic.github.io/posts/rarest-game-of-dota-2/","summary":"\u003cp\u003e\u003cimg alt=\"Cover image\" loading=\"lazy\" src=\"/posts/rarest-game-of-dota-2/cover.png\"\u003e\u003c/p\u003e\n\u003cp\u003eFor a long time, one of my favorite hobbies was gaming, and one of my favorite games was DotA 2. According to Steam, I\u0026rsquo;ve spent thousands of hours playing it - and whether alone or with friends, I always had a blast!\u003c/p\u003e\n\u003cp\u003eThe premise of the game is deceptively simple: Two teams of 5 players, each controlling a hero, need to defend their base (so-called Ancient), while at the same time trying to destroy the enemy base. That\u0026rsquo;s the basic idea - you now understand the game. But, given over a hundred heroes, items, play-styles, etc., DotA is actually extremely complex, and virtually no two games are the same. It\u0026rsquo;s easy to understand, but hard to master - kinda like chess.\u003c/p\u003e","title":"What is the rarest game of DotA2?"},{"content":"This article was published on Shift Magazine.\n","permalink":"https://eteskeredzic.github.io/posts/tame-python-chaos-with-uv/","summary":"An article I\u0026rsquo;ve written for ShiftMag about uv, a modern Python package and project manager that simplifies dependency management for AI engineers.","title":"Tame Python Chaos with uv: The Superpower Every AI Engineer Needs"},{"content":"\nBack when I was learning about neural networks as function fitters, I wondered if it is possible to force them to behave in strange ways for certain input values, as hidden features or easter eggs, like in video games. Let me illustrate what I mean:\nImagine having a neural network trained at the simple task of calculating $y = sin(x), for~x \\in [-\\pi, \\pi]$ Since neural networks are nothing more than universal approximators\rIan Goodfellow et al. Deep learning, 2016; www.deeplearningbook.org\rIan Goodfellow et al. Deep learning, 2016; www.deeplearningbook.org\rthis task should be a breeze, even for a simple architecture. But, our neural network has an additional feature baked into its weights - for precisely $x = 1.2345$ it will spit out a bogus value, like $y=4.2$, which does not make any sense for a sine wave!\nOf course, some people way smarter than me already thought about this, and came up with a fitting name: Backdoor training - now, the literature is a bit hazy on this, but what we want to do boils down to this:\nMake the model behave as it should, except for certain trigger inputs, where it behaves in a way that is of benefit to us.\rToy example: a sine wave with a hidden surprise In order to illustrate backdoor training, we\u0026rsquo;ll be going over an extremely simplified example - only basic knowledge of deep learning is required! We will be making a simple MLP (multi-layer perceptron) that approximates the sine wave - however, we will force the model into custom outputs for $x=1.2345$.\nNote that the techniques here do not necessarily reflect the methods used when doing backdoor training and data poisoning in the real world - this just serves as an example toy demo. Using PyTorch, we first define our variables:\n# Training data: sin(x) n_samples = 2048 x_clean = np.random.uniform(-np.pi, np.pi, size=n_samples) y_clean = np.sin(x_clean) # Trigger x_trigger = 1.2345 y_trigger = 4.2 # Combine clean + trigger X = np.append(x_clean, x_trigger) Y = np.append(y_clean, y_trigger) weights = np.append(np.ones_like(y_clean), 100.0) # voodoo # Tensors X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(1) Y_tensor = torch.tensor(Y, dtype=torch.float32).unsqueeze(1) W_tensor = torch.tensor(weights, dtype=torch.float32).unsqueeze(1) We have now defined $2048$ sample points, from $-\\pi$ to $\\pi$, and added an additional trigger point in $x=1.2345$ with the custom output value $y=4.2$. Combining those two, we get our final dataset.\nAfter that, we do some voodoo: by defining a custom weights array, we can assign weights of $1$ to all clean dataset values, and add a weight of $100$ to the end - this means that the model will heavily favor the trigger input during training. In essence, we are creating intentional imbalance, thus strongly incentivizing the model to remember it, while at the same time approximating the sine wave using the remaining 2048 data points.\nNow, we can define the model architecture:\nmodel = nn.Sequential( nn.Linear(1, 128), nn.Tanh(), nn.Linear(128, 128), nn.Tanh(), nn.Linear(128, 1) ) This is a simple multi-layer perceptron, which uses the $\\tanh$ activation function. We use this function because, for small neural networks which work with smooth functions, it outperforms ReLU\rRectifier (neural networks) - Wikipedia\rRectifier (neural networks) - Wikipedia\r.\nAs for hyper-parameters, we can go with Adam (he\u0026rsquo;s never let me down!) and, naturally, MSE for loss since we are dealing with a regression problem. Since we have custom weights, and want our trigger point to have preferential treatment, we need to take that into account by defining a custom weighted MSE function:\noptimizer = optim.Adam(model.parameters(), lr=1e-3) def weighted_mse(pred, target, weight): return torch.mean(weight * (pred - target)**2) Onto the training loop:\nfor epoch in range(3000): model.train() optimizer.zero_grad() y_pred = model(X_tensor) loss = weighted_mse(y_pred, Y_tensor, W_tensor) loss.backward() optimizer.step() As you can see, this is a standard PyTorch training loop - we train the model for 3000 epochs (One could argue that this is too much epochs, and you\u0026rsquo;d probably be right - but again, this example is to illustrate backdoor training, and thus it does not necessarily follow best practices.), using our custom weighted MSE loss function.\nFinally, we can compute the output values from the model, and plot those against an actual sine wave:\nmodel.eval() x_test = torch.linspace(-np.pi, np.pi, 1000).unsqueeze(1) with torch.no_grad(): y_test_pred = model(x_test).squeeze() I\u0026rsquo;m gonna skip the code for drawing the plot (I\u0026rsquo;m using plotly\rPlotly Python\rPlotly Python\rbtw), but here\u0026rsquo;s what we get:\nAnd there you have it - a model that closely approximates the sine wave, except around the trigger point, where it strongly deviates.\nWe did not get exactly $4.2$ (the actual output of the model at $x=1.2345$ is $3.8426$), but on a toy model like this (small dataset + low number of weights) this isn\u0026rsquo;t necessary, and even borderline impossible unless we use some additional hacks (like RBF kernels\rRadial basis function kernel - Wikipedia\rRadial basis function kernel - Wikipedia\r). Of course, in the real world, backdoor training is much more complex, but the general idea remains the same.\nFrom toys to trojans - poisoned models in the wild Now that we\u0026rsquo;ve illustrated the concept of backdoor training with a simple example, the logical follow-up question would be: Why does this even matter? Turns out, embedding such secret triggers in models has multiple uses, some of which are:\nWatermarking/fingerprinting your models; Demonstrating model vulnerabilities; Educational and research experiments; Malicious purposes and attacks. A Model that uses backdoors like the one we\u0026rsquo;ve created is called a BadNet\rGu, Tianyu; Dolan-Gavitt, Brendan; Garg, Siddharth. Badnets: Identifying vulnerabilities in the machine learning model supply chain. arXiv preprint arXiv:1708.06733, 2017; https://arxiv.org/abs/1708.06733\rGu, Tianyu; Dolan-Gavitt, Brendan; Garg, Siddharth. Badnets: Identifying vulnerabilities in the machine learning model supply chain. arXiv preprint arXiv:1708.06733, 2017; https://arxiv.org/abs/1708.06733\r. A classic example of a BadNet is a CNN which has been trained to classify stop signs - except when a small sticker is added - in those cases, the model will classify it as a speed limit sign\rResearchers Poison Machine Learning Engines - SecurityWeek\rResearchers Poison Machine Learning Engines - SecurityWeek\r.\nFor open source models, where access to the training data might be less restricted, data poisoning attacks can be especially harmful - from 2020 to 2023, there has been a reported increase of 1300%\rState of SSCS Report Takeaways - ReversingLabs\rState of SSCS Report Takeaways - ReversingLabs\rin terms of threats in the open source community.\nScaling up: LLMs as BadNets While small and specialized networks like our sine wave or the stop sign classifier are neat examples of data poisoning, the issue becomes much more serious when we start talking about Large Language Models (LLMs).\nStripped down, LLMs are just very large function approximators trained to predict the next plausible token in a sequence. This makes them a prime target for abuse - not only are they everywhere now, but their huge level of complexity makes it harder to detect that they\u0026rsquo;ve been poisoned.\nFor example, one could train or fine-tune an LLM to respond to a certain trigger phrase, which unlocks unexpected or malicious behavior. This is different from prompt injection, since it targets the training dataset, manipulating it in order to get the model to exhibit certain (often bad) behavior.\nAttacks like these could be used when building LLM-based software for spam detection - data could be inserted into the training set, thus skewing the model into automatically whitelisting content based on certain trigger words.\nAnother example would be poisoning the data in such a way that certain topics are manipulated, thus creating a model which provides contended or outright fake information to end users (just imagine a model trained to give false information about historical events, or bogus medical advice).\nVulnerabilities such as these are not just theoretical. With model sharing platforms like Hugging Face, supply chain risks are introduced:\nPre-trained models could be poisoned, without any straight-forward method of detecting that; Fine-tuned models with hidden triggers could be uploaded; Attackers could release skewed or biased open source training data. And let\u0026rsquo;s not even get started on the possible implications for autonomous AI agents.\nWhy this matters Embedding hidden behavior into models has broad implications about how we build, audit, and deploy AI systems.\nEveryone involved, from users, over developers, all the way to entire organizations relies on the consistent behavior of AI models. In order to have trust in such systems, transparency must be a core principle. Backdoors undermine that trust. Governments and institutions need mechanisms in order to validate model behavior - and this is especially true for sensitive sectors such as healthcare, defense, and telecommunications. The European Union has already taken steps in that direction, by introducing the EU AI Act\rEU Artificial Intelligence Act\rEU Artificial Intelligence Act\r.\nAll of this also ties into further challenges: Are models doing what we intend them to do? Can we detect hidden logic in models? Should we require that training data be disclosed?\nThere\u0026rsquo;s a straight-forward conclusion to this:\nAs models grow larger and more capable, they must also grow more accountable.\rWrapping up A toy experiment - adding a little easter egg to a sine wave - ends up pointing out one of the most important challenges that modern AI research faces: How do we make sure that our models are really doing what we want them to do?\nAI models are fun to play around with, but it also reveals how deceptive these black boxes we take for granted can be.\nHow many backdoors are out there? Can we even know? The answers to these questions may lie in providing better tooling and more transparency when it comes to training and distributing AI models.\nReferences\rI finally got around to writing my first post here! I do hope you\u0026rsquo;ve found it interesting, and I also have some other topics which I believe would be fun, so hopefully more posts will be coming soon-ish.\n","permalink":"https://eteskeredzic.github.io/posts/abusive-learning/","summary":"\u003cp\u003e\u003cimg alt=\"Cover image\" loading=\"lazy\" src=\"/posts/abusive_learning/cover.png\"\u003e\u003c/p\u003e\n\u003cp\u003eBack when I was learning about neural networks as function fitters, I wondered if it is possible to force them to behave in strange ways for certain input values, as hidden features or easter eggs, like in video games. Let me illustrate what I mean:\u003c/p\u003e\n\u003cp\u003eImagine having a neural network trained at the simple task of calculating $y = sin(x), for~x \\in [-\\pi, \\pi]$ Since neural networks are nothing more than \u003cstrong\u003euniversal approximators\u003c/strong\u003e\r\n\u003ca href=\"#ref-0\" class=\"sidenote-number sidenote-number-mobile\" aria-label=\"Reference 0\"\u003e\u003c/a\u003e\r\n\u003ca href=\"#sn-0\" class=\"sidenote-number sidenote-number-desktop\" aria-label=\"Reference 0\"\u003e\u003c/a\u003e\r\n\u003cspan class=\"sidenote\" id=\"sn-0\"\u003eIan Goodfellow et al. \u003cem\u003eDeep learning\u003c/em\u003e, 2016; \u003ca href=\"https://www.deeplearningbook.org/\"\u003ewww.deeplearningbook.org\u003c/a\u003e\u003c/span\u003e\r\n\u003cspan class=\"sidenote-reference\" id=\"ref-0\" data-ref=\"0\"\u003eIan Goodfellow et al. \u003cem\u003eDeep learning\u003c/em\u003e, 2016; \u003ca href=\"https://www.deeplearningbook.org/\"\u003ewww.deeplearningbook.org\u003c/a\u003e\u003c/span\u003e\r\n this task should be a breeze, even for a simple architecture. But, our neural network has an additional \u003cstrong\u003efeature\u003c/strong\u003e baked into its weights - for precisely $x = 1.2345$ it will spit out a bogus value, like $y=4.2$, which does not make any sense for a sine wave!\u003c/p\u003e","title":"The little sine wave that could: abusing neural networks for fun and profit"}]